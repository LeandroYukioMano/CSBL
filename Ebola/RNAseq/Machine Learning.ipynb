{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest, RFECV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARC1</th>\n",
       "      <th>MARCH1</th>\n",
       "      <th>MARC2</th>\n",
       "      <th>MARCH2</th>\n",
       "      <th>MARCH3</th>\n",
       "      <th>MARCH5</th>\n",
       "      <th>MARCH6</th>\n",
       "      <th>MARCH7</th>\n",
       "      <th>MARCH8</th>\n",
       "      <th>MARCH9</th>\n",
       "      <th>...</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G305</th>\n",
       "      <td>0.242012</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.423837</td>\n",
       "      <td>0.383878</td>\n",
       "      <td>0.549269</td>\n",
       "      <td>0.118496</td>\n",
       "      <td>0.265228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200853</td>\n",
       "      <td>0.196095</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.313864</td>\n",
       "      <td>0.431619</td>\n",
       "      <td>0.716832</td>\n",
       "      <td>0.726968</td>\n",
       "      <td>0.589935</td>\n",
       "      <td>0.557249</td>\n",
       "      <td>0.697976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G102</th>\n",
       "      <td>0.097947</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.057645</td>\n",
       "      <td>0.292160</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>0.280620</td>\n",
       "      <td>0.277724</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.154169</td>\n",
       "      <td>0.355240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569036</td>\n",
       "      <td>0.114953</td>\n",
       "      <td>0.294043</td>\n",
       "      <td>0.303472</td>\n",
       "      <td>0.753035</td>\n",
       "      <td>0.215427</td>\n",
       "      <td>0.419179</td>\n",
       "      <td>0.295388</td>\n",
       "      <td>0.592959</td>\n",
       "      <td>0.307296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G120</th>\n",
       "      <td>0.175804</td>\n",
       "      <td>0.499479</td>\n",
       "      <td>0.462908</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>0.256344</td>\n",
       "      <td>0.894201</td>\n",
       "      <td>0.533709</td>\n",
       "      <td>0.950390</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>0.200807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301122</td>\n",
       "      <td>0.367244</td>\n",
       "      <td>0.110495</td>\n",
       "      <td>0.252498</td>\n",
       "      <td>0.546039</td>\n",
       "      <td>0.275148</td>\n",
       "      <td>0.820298</td>\n",
       "      <td>0.629097</td>\n",
       "      <td>0.392440</td>\n",
       "      <td>0.234136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G105</th>\n",
       "      <td>0.208543</td>\n",
       "      <td>0.182351</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>0.179667</td>\n",
       "      <td>0.248777</td>\n",
       "      <td>0.105611</td>\n",
       "      <td>0.366059</td>\n",
       "      <td>0.161228</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>0.749766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528351</td>\n",
       "      <td>0.371722</td>\n",
       "      <td>0.956183</td>\n",
       "      <td>0.562884</td>\n",
       "      <td>0.051608</td>\n",
       "      <td>0.564213</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G304</th>\n",
       "      <td>0.105972</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>0.189626</td>\n",
       "      <td>0.406686</td>\n",
       "      <td>0.557530</td>\n",
       "      <td>0.220183</td>\n",
       "      <td>0.421494</td>\n",
       "      <td>0.377251</td>\n",
       "      <td>0.226414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120617</td>\n",
       "      <td>0.295468</td>\n",
       "      <td>0.522655</td>\n",
       "      <td>0.145206</td>\n",
       "      <td>0.185419</td>\n",
       "      <td>0.392535</td>\n",
       "      <td>0.338361</td>\n",
       "      <td>0.305716</td>\n",
       "      <td>0.620625</td>\n",
       "      <td>0.292157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MARC1    MARCH1     MARC2    MARCH2    MARCH3    MARCH5    MARCH6  \\\n",
       "G305  0.242012  0.160667  0.334218  0.128834  0.423837  0.383878  0.549269   \n",
       "G102  0.097947  0.969388  0.057645  0.292160  0.011729  0.280620  0.277724   \n",
       "G120  0.175804  0.499479  0.462908  0.152632  0.256344  0.894201  0.533709   \n",
       "G105  0.208543  0.182351  0.062311  0.179667  0.248777  0.105611  0.366059   \n",
       "G304  0.105972  0.767500  0.037707  0.189626  0.406686  0.557530  0.220183   \n",
       "\n",
       "        MARCH7    MARCH8    MARCH9  ...      ZW10    ZWILCH     ZWINT  \\\n",
       "G305  0.118496  0.265228  1.000000  ...  0.200853  0.196095  0.417100   \n",
       "G102  0.613370  0.154169  0.355240  ...  0.569036  0.114953  0.294043   \n",
       "G120  0.950390  0.205718  0.200807  ...  0.301122  0.367244  0.110495   \n",
       "G105  0.161228  0.173616  0.749766  ...  0.169052  0.000000  0.528351   \n",
       "G304  0.421494  0.377251  0.226414  ...  0.120617  0.295468  0.522655   \n",
       "\n",
       "          ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1      ZZZ3  \n",
       "G305  0.313864  0.431619  0.716832  0.726968  0.589935  0.557249  0.697976  \n",
       "G102  0.303472  0.753035  0.215427  0.419179  0.295388  0.592959  0.307296  \n",
       "G120  0.252498  0.546039  0.275148  0.820298  0.629097  0.392440  0.234136  \n",
       "G105  0.371722  0.956183  0.562884  0.051608  0.564213  0.099206  1.000000  \n",
       "G304  0.145206  0.185419  0.392535  0.338361  0.305716  0.620625  0.292157  \n",
       "\n",
       "[5 rows x 14279 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_csv('Dados/Tratado-csv/1v0.csv',header=0,index_col=0)\n",
    "dados.index.name='Probes'\n",
    "ae = pd.read_csv('Dados/Tratado-csv/AdverseEvent.csv',index_col=0)\n",
    "ar = pd.read_csv('Dados/Tratado-csv/AntibodyResponse.csv',index_col=0)\n",
    "dados = pd.concat([dados,ae,ar],axis=1)\n",
    "dados = dados.dropna(how='any',axis=0)\n",
    "X = dados.drop(dados.columns[-2:],axis=1)\n",
    "genes = np.array(X.columns)\n",
    "y_ae = dados[dados.columns[-2]]\n",
    "y_ar = dados[dados.columns[-1]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var=[]\n",
    "for col in X.columns:\n",
    "    var.append(X[col].var())\n",
    "interval = 0.005\n",
    "size = 20\n",
    "bins = [i*interval for i in range(size)]\n",
    "fig, ax = plt.subplots(figsize =(10, 7)) \n",
    "ax.hist(var,bins = bins);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lines probes with `var` < `treshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 14279)\n",
      "(30, 7565)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARCH1</th>\n",
       "      <th>MARC2</th>\n",
       "      <th>MARCH2</th>\n",
       "      <th>MARCH3</th>\n",
       "      <th>MARCH5</th>\n",
       "      <th>MARCH7</th>\n",
       "      <th>MARCH9</th>\n",
       "      <th>SEPT1</th>\n",
       "      <th>SEPT5</th>\n",
       "      <th>SEPT6</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSCAN30</th>\n",
       "      <th>ZSWIM3</th>\n",
       "      <th>ZSWIM6</th>\n",
       "      <th>ZUFSP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160667</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.423837</td>\n",
       "      <td>0.383878</td>\n",
       "      <td>0.118496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374424</td>\n",
       "      <td>0.364903</td>\n",
       "      <td>0.243756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0.238057</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200853</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.431619</td>\n",
       "      <td>0.716832</td>\n",
       "      <td>0.589935</td>\n",
       "      <td>0.697976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.057645</td>\n",
       "      <td>0.292160</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>0.280620</td>\n",
       "      <td>0.613370</td>\n",
       "      <td>0.355240</td>\n",
       "      <td>0.584297</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>0.393642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122696</td>\n",
       "      <td>0.649423</td>\n",
       "      <td>0.777812</td>\n",
       "      <td>0.175056</td>\n",
       "      <td>0.569036</td>\n",
       "      <td>0.294043</td>\n",
       "      <td>0.753035</td>\n",
       "      <td>0.215427</td>\n",
       "      <td>0.295388</td>\n",
       "      <td>0.307296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499479</td>\n",
       "      <td>0.462908</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>0.256344</td>\n",
       "      <td>0.894201</td>\n",
       "      <td>0.950390</td>\n",
       "      <td>0.200807</td>\n",
       "      <td>0.685460</td>\n",
       "      <td>0.391286</td>\n",
       "      <td>0.552908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277317</td>\n",
       "      <td>0.332328</td>\n",
       "      <td>0.301122</td>\n",
       "      <td>0.110495</td>\n",
       "      <td>0.546039</td>\n",
       "      <td>0.275148</td>\n",
       "      <td>0.629097</td>\n",
       "      <td>0.234136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182351</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>0.179667</td>\n",
       "      <td>0.248777</td>\n",
       "      <td>0.105611</td>\n",
       "      <td>0.161228</td>\n",
       "      <td>0.749766</td>\n",
       "      <td>0.592156</td>\n",
       "      <td>0.614202</td>\n",
       "      <td>0.642848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228498</td>\n",
       "      <td>0.286919</td>\n",
       "      <td>0.258031</td>\n",
       "      <td>0.044801</td>\n",
       "      <td>0.169052</td>\n",
       "      <td>0.528351</td>\n",
       "      <td>0.956183</td>\n",
       "      <td>0.562884</td>\n",
       "      <td>0.564213</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767500</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>0.189626</td>\n",
       "      <td>0.406686</td>\n",
       "      <td>0.557530</td>\n",
       "      <td>0.421494</td>\n",
       "      <td>0.226414</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.420510</td>\n",
       "      <td>0.271168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120668</td>\n",
       "      <td>0.408151</td>\n",
       "      <td>0.318812</td>\n",
       "      <td>0.177021</td>\n",
       "      <td>0.120617</td>\n",
       "      <td>0.522655</td>\n",
       "      <td>0.185419</td>\n",
       "      <td>0.392535</td>\n",
       "      <td>0.305716</td>\n",
       "      <td>0.292157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7565 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MARCH1     MARC2    MARCH2    MARCH3    MARCH5    MARCH7    MARCH9  \\\n",
       "0  0.160667  0.334218  0.128834  0.423837  0.383878  0.118496  1.000000   \n",
       "1  0.969388  0.057645  0.292160  0.011729  0.280620  0.613370  0.355240   \n",
       "2  0.499479  0.462908  0.152632  0.256344  0.894201  0.950390  0.200807   \n",
       "3  0.182351  0.062311  0.179667  0.248777  0.105611  0.161228  0.749766   \n",
       "4  0.767500  0.037707  0.189626  0.406686  0.557530  0.421494  0.226414   \n",
       "\n",
       "      SEPT1     SEPT5     SEPT6  ...   ZSCAN30    ZSWIM3    ZSWIM6     ZUFSP  \\\n",
       "0  0.374424  0.364903  0.243756  ...  0.718769  0.238057  0.280264  0.000000   \n",
       "1  0.584297  0.190682  0.393642  ...  0.122696  0.649423  0.777812  0.175056   \n",
       "2  0.685460  0.391286  0.552908  ...  0.868514  1.000000  0.277317  0.332328   \n",
       "3  0.592156  0.614202  0.642848  ...  0.228498  0.286919  0.258031  0.044801   \n",
       "4  0.292800  0.420510  0.271168  ...  0.120668  0.408151  0.318812  0.177021   \n",
       "\n",
       "       ZW10     ZWINT      ZXDB      ZXDC       ZYX      ZZZ3  \n",
       "0  0.200853  0.417100  0.431619  0.716832  0.589935  0.697976  \n",
       "1  0.569036  0.294043  0.753035  0.215427  0.295388  0.307296  \n",
       "2  0.301122  0.110495  0.546039  0.275148  0.629097  0.234136  \n",
       "3  0.169052  0.528351  0.956183  0.562884  0.564213  1.000000  \n",
       "4  0.120617  0.522655  0.185419  0.392535  0.305716  0.292157  \n",
       "\n",
       "[5 rows x 7565 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treshold = 5e-2\n",
    "print(X.shape)\n",
    "selector = VarianceThreshold(treshold)\n",
    "X = selector.fit_transform(X)\n",
    "print(X.shape)\n",
    "index = np.where(selector.get_support()==True)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = genes[index]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adverse Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t8\n",
      "Rejected: \t7557\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t6\n",
      "Rejected: \t7557\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t6\n",
      "Rejected: \t7557\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t5\n",
      "Rejected: \t7557\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t4\n",
      "Rejected: \t7557\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t3\n",
      "Rejected: \t7557\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t2\n",
      "Rejected: \t7557\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t2\n",
      "Rejected: \t7557\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t1\n",
      "Rejected: \t7557\n"
     ]
    }
   ],
   "source": [
    "X_ae = X\n",
    "\n",
    "forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=15)\n",
    "forest.fit(np.array(X_ae), np.array(y_ae).ravel())\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=42)\n",
    "feat_selector.fit(np.array(X_ae), np.array(y_ae).ravel())\n",
    "feature_ranks_ae = list(zip(X_ae.columns, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "features_ae = []\n",
    "for feat in feature_ranks_ae:\n",
    "    if feat[2]:\n",
    "        features_ae.append(feat[0])\n",
    "X_ae = X_ae[features_ae]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAMDC</th>\n",
       "      <th>ABO</th>\n",
       "      <th>ACYP2</th>\n",
       "      <th>ALKBH3</th>\n",
       "      <th>AP4B1</th>\n",
       "      <th>APAF1</th>\n",
       "      <th>APPBP2</th>\n",
       "      <th>ARAP3</th>\n",
       "      <th>ARHGAP23</th>\n",
       "      <th>ARHGAP5</th>\n",
       "      <th>...</th>\n",
       "      <th>LOC286367</th>\n",
       "      <th>LOC389906</th>\n",
       "      <th>LOC441454</th>\n",
       "      <th>LY86</th>\n",
       "      <th>LYSMD1</th>\n",
       "      <th>MAML1</th>\n",
       "      <th>MANEAL</th>\n",
       "      <th>MAP3K8</th>\n",
       "      <th>MATK</th>\n",
       "      <th>MBD2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341546</td>\n",
       "      <td>0.039805</td>\n",
       "      <td>0.631672</td>\n",
       "      <td>0.506658</td>\n",
       "      <td>0.467282</td>\n",
       "      <td>0.863378</td>\n",
       "      <td>0.261259</td>\n",
       "      <td>0.113562</td>\n",
       "      <td>0.060405</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.123071</td>\n",
       "      <td>0.950796</td>\n",
       "      <td>0.560368</td>\n",
       "      <td>0.855394</td>\n",
       "      <td>0.297311</td>\n",
       "      <td>0.365958</td>\n",
       "      <td>0.179749</td>\n",
       "      <td>0.741572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.107631</td>\n",
       "      <td>0.429177</td>\n",
       "      <td>0.521714</td>\n",
       "      <td>0.391022</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.375626</td>\n",
       "      <td>0.136572</td>\n",
       "      <td>0.197362</td>\n",
       "      <td>0.125542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551249</td>\n",
       "      <td>0.074359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100688</td>\n",
       "      <td>0.369743</td>\n",
       "      <td>0.272301</td>\n",
       "      <td>0.312025</td>\n",
       "      <td>0.395705</td>\n",
       "      <td>0.298790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232293</td>\n",
       "      <td>0.122255</td>\n",
       "      <td>0.628704</td>\n",
       "      <td>0.247820</td>\n",
       "      <td>0.157624</td>\n",
       "      <td>0.048185</td>\n",
       "      <td>0.170937</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>0.086236</td>\n",
       "      <td>0.452498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211813</td>\n",
       "      <td>0.275251</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.525898</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.542641</td>\n",
       "      <td>0.193587</td>\n",
       "      <td>0.241475</td>\n",
       "      <td>0.243461</td>\n",
       "      <td>0.156616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.146955</td>\n",
       "      <td>0.156305</td>\n",
       "      <td>0.861992</td>\n",
       "      <td>0.410327</td>\n",
       "      <td>0.670866</td>\n",
       "      <td>0.401760</td>\n",
       "      <td>0.510160</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>0.190013</td>\n",
       "      <td>0.331652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531715</td>\n",
       "      <td>0.237656</td>\n",
       "      <td>0.397096</td>\n",
       "      <td>0.192013</td>\n",
       "      <td>0.077470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>0.525299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102039</td>\n",
       "      <td>0.246682</td>\n",
       "      <td>0.569008</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>0.439132</td>\n",
       "      <td>0.435561</td>\n",
       "      <td>0.610962</td>\n",
       "      <td>0.135712</td>\n",
       "      <td>0.238244</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170504</td>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.274594</td>\n",
       "      <td>0.371275</td>\n",
       "      <td>0.231626</td>\n",
       "      <td>0.674535</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.313410</td>\n",
       "      <td>0.184295</td>\n",
       "      <td>0.433874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAMDC       ABO     ACYP2    ALKBH3     AP4B1     APAF1    APPBP2  \\\n",
       "0  0.341546  0.039805  0.631672  0.506658  0.467282  0.863378  0.261259   \n",
       "1  0.010585  0.107631  0.429177  0.521714  0.391022  0.937715  0.375626   \n",
       "2  0.232293  0.122255  0.628704  0.247820  0.157624  0.048185  0.170937   \n",
       "3  0.146955  0.156305  0.861992  0.410327  0.670866  0.401760  0.510160   \n",
       "4  0.102039  0.246682  0.569008  0.183832  0.439132  0.435561  0.610962   \n",
       "\n",
       "      ARAP3  ARHGAP23   ARHGAP5  ...  LOC286367  LOC389906  LOC441454  \\\n",
       "0  0.113562  0.060405  0.243100  ...   1.000000   0.030421   0.123071   \n",
       "1  0.136572  0.197362  0.125542  ...   0.551249   0.074359   0.000000   \n",
       "2  0.332689  0.086236  0.452498  ...   0.211813   0.275251   0.297463   \n",
       "3  0.500556  0.190013  0.331652  ...   0.531715   0.237656   0.397096   \n",
       "4  0.135712  0.238244  0.100378  ...   0.170504   0.265218   0.274594   \n",
       "\n",
       "       LY86    LYSMD1     MAML1    MANEAL    MAP3K8      MATK      MBD2  \n",
       "0  0.950796  0.560368  0.855394  0.297311  0.365958  0.179749  0.741572  \n",
       "1  1.000000  0.100688  0.369743  0.272301  0.312025  0.395705  0.298790  \n",
       "2  0.525898  0.818862  0.542641  0.193587  0.241475  0.243461  0.156616  \n",
       "3  0.192013  0.077470  1.000000  0.036865  0.356986  0.044421  0.525299  \n",
       "4  0.371275  0.231626  0.674535  0.012607  0.313410  0.184295  0.433874  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ae = X\n",
    "anova =  SelectKBest(f_classif, k=100).fit(X_ae, y_ae)\n",
    "X_ae = pd.DataFrame(anova.fit_transform(X_ae,y_ae))\n",
    "index = np.where(anova.get_support()==True)\n",
    "X_ae.columns = genes[index]\n",
    "X_ae.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_ae, y_ae = sm.fit_resample(X_ae, y_ae)\n",
    "y_ae = pd.DataFrame(y_ae)\n",
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid, model,w=None,h=None,df=None,plot=None,annot=None):\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,\n",
    "                      param_grid=param_grid,\n",
    "                      cv=kfold)\n",
    "    best_gs = gs.fit(X_train,y_train)\n",
    "    n = len(param_grid)\n",
    "    scores = best_gs.cv_results_['mean_test_score']\n",
    "    scores = scores.reshape(len(scores),)\n",
    "    \n",
    "    if n == 1 and plot:\n",
    "        label = list(param_grid.keys())[0]\n",
    "        par = list(param_grid.values())[0]\n",
    "        plt.plot(par,scores)\n",
    "        plt.ylabel('F1-score')\n",
    "        plt.xlabel(label)\n",
    "        plt.show()\n",
    "        \n",
    "    if n == 2 and plot:\n",
    "        \n",
    "        label1,label2 = param_grid.keys()\n",
    "        par1,par2 = param_grid.values()\n",
    "        scores_df = pd.DataFrame(columns=par1,index=par2)\n",
    "        for i in range(len(par1)*len(par2)):\n",
    "            col = i % len(par1)\n",
    "            row = i // len(par1)\n",
    "            scores_df.iloc[row,col] = scores[i]\n",
    "\n",
    "        scores_df = scores_df.astype(float)\n",
    "        if df:\n",
    "            print(scores_df)\n",
    "        if plot:\n",
    "            fig= plt.figure(figsize=(w,h))\n",
    "            heatmap = sns.heatmap(scores_df,annot=annot)        \n",
    "            plt.xlabel(label1)\n",
    "            plt.ylabel(label2)\n",
    "            plt.show()\n",
    "\n",
    "    return best_gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Trees: max_depth=3, criterion=gini\n",
      "KNN: n_neighbors=1, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=hinge, alpha=0.0001, penalty=l2\n",
      "SVC: C=1, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.83, KNN=0.83, RF=0.91, SGD=0.83, SVC=0.91\n",
      "\n",
      "Round 2:\n",
      "Trees: max_depth=2, criterion=gini\n",
      "KNN: n_neighbors=2, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=hinge, alpha=1e-05, penalty=l2\n",
      "SVC: C=1, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.8, KNN=0.83, RF=0.73, SGD=0.91, SVC=0.83\n",
      "\n",
      "Round 3:\n",
      "Trees: max_depth=2, criterion=gini\n",
      "KNN: n_neighbors=2, algorithm=auto\n",
      "RF: n_estimators=158\n",
      "SGD: loss=hinge, alpha=1e-05, penalty=l2\n",
      "SVC: C=1, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.93, KNN=1.0, RF=1.0, SGD=1.0, SVC=1.0\n",
      "\n",
      "Round 4:\n",
      "Trees: max_depth=3, criterion=gini\n",
      "KNN: n_neighbors=1, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=perceptron, alpha=0.001, penalty=l1\n",
      "SVC: C=5, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.83, KNN=0.91, RF=0.91, SGD=0.83, SVC=0.91\n",
      "\n",
      "Round 5:\n",
      "Trees: max_depth=1, criterion=gini\n",
      "KNN: n_neighbors=1, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=perceptron, alpha=1e-05, penalty=l1\n",
      "SVC: C=5, gamma=auto\n",
      "\n",
      "F1 scores: Trees=0.5, KNN=0.91, RF=0.91, SGD=0.91, SVC=0.91\n",
      "\n",
      "\n",
      "Total F1 scores: Trees=0.78, KNN=0.9, RF=0.89, SGD=0.9, SVC = 0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "test_size = 0.3\n",
    "n_folds = 5\n",
    "kfold = KFold(n_folds,shuffle=True,random_state=42)\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "#Decision Trees\n",
    "param_grid_tree = {'max_depth':[1,2,3,4,5],\n",
    "                   'criterion':['gini','entropy']\n",
    "                  }\n",
    "\n",
    "#KNN\n",
    "param_grid_knn = {'n_neighbors':[1,2,3,4,5],\n",
    "                  'algorithm':['auto','ball_tree','kd_tree','brute']\n",
    "                 }\n",
    "\n",
    "#Random Forest\n",
    "param_grid_rf = {'n_estimators':[150,158,166,174,182]}\n",
    "\n",
    "#SGD\n",
    "param_grid_sgd = {'loss':['hinge', 'perceptron'],\n",
    "                 'penalty':['l2', 'l1', 'elasticnet'],\n",
    "                 'alpha':[1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "                 }\n",
    "\n",
    "#SVC\n",
    "param_grid_svc = {'C':[1, 5, 10, 50, 100,],\n",
    "                  'gamma':['scale','auto']\n",
    "                 }\n",
    "\n",
    "tree_score= .0\n",
    "knn_score= .0\n",
    "rf_score= .0\n",
    "sgd_score= .0\n",
    "svc_score=.0\n",
    "\n",
    "rounds = 0\n",
    "\n",
    "for train_index, test_index in sss.split(X_ae, y_ae):\n",
    "    print(f'Round {rounds+1}:')\n",
    "    X_train,X_test,y_train,y_test = X_ae.iloc[train_index],X_ae.iloc[test_index],y_ae.iloc[train_index],y_ae.iloc[test_index]\n",
    "    \n",
    "    #Decision trees\n",
    "    hp_tree= get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_tree,DecisionTreeClassifier(random_state=42))\n",
    "    criterion_opt,max_depth_opt = hp_tree.values()\n",
    "    print(f'Trees: max_depth={max_depth_opt}, criterion={criterion_opt}')\n",
    "    tree = make_pipeline(StandardScaler(),\n",
    "                         DecisionTreeClassifier(\n",
    "                            random_state=42,\n",
    "                            criterion=criterion_opt,\n",
    "                            max_depth=max_depth_opt,\n",
    "                         )\n",
    "                        )\n",
    "    tree.fit(X_train,y_train)\n",
    "    pred_tree = tree.predict(X_test)\n",
    "    f1_tree = round(f1_score(y_test,pred_tree),2)\n",
    "    tree_score += f1_tree\n",
    "    \n",
    "    #KNN\n",
    "    hp_knn = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_knn,KNeighborsClassifier())\n",
    "    algorithm_opt,n_neighbors_opt = hp_knn.values()\n",
    "    print(f'KNN: n_neighbors={n_neighbors_opt}, algorithm={algorithm_opt}')\n",
    "    knn = make_pipeline(StandardScaler(),\n",
    "                        KNeighborsClassifier(\n",
    "                            n_neighbors=n_neighbors_opt,\n",
    "                            algorithm=algorithm_opt\n",
    "                        )\n",
    "                       )\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_knn = knn.predict(X_test)\n",
    "    f1_knn = round(f1_score(y_test,pred_knn),2)\n",
    "    knn_score += f1_knn\n",
    "    \n",
    "    #Random Forest\n",
    "    hp_rf = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_rf,RandomForestClassifier())\n",
    "    n_estimators_opt = list(hp_rf.values())[0]\n",
    "    print(f'RF: n_estimators={n_estimators_opt}')\n",
    "    rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(\n",
    "                            n_estimators=n_estimators_opt\n",
    "                        )\n",
    "                       )\n",
    "    rf.fit(X_train,y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "    f1_rf = round(f1_score(y_test,pred_rf),2)\n",
    "    rf_score += f1_rf\n",
    "    \n",
    "    #SGD\n",
    "    hp_sgd = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_sgd,SGDClassifier())\n",
    "    alpha_opt,loss_opt,penalty_opt = hp_sgd.values()\n",
    "    print(f'SGD: loss={loss_opt}, alpha={alpha_opt}, penalty={penalty_opt}')\n",
    "    sgd = make_pipeline(StandardScaler(),\n",
    "                        SGDClassifier(\n",
    "                            loss=loss_opt,\n",
    "                            alpha=alpha_opt,\n",
    "                            penalty=penalty_opt\n",
    "                        )\n",
    "                       )\n",
    "    sgd.fit(X_train,y_train)\n",
    "    pred_sgd = sgd.predict(X_test)\n",
    "    f1_sgd = round(f1_score(y_test,pred_sgd),2)\n",
    "    sgd_score += f1_sgd\n",
    "    \n",
    "    #SVC\n",
    "    hp_svc = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_svc,SVC())\n",
    "    c_opt,gamma_opt = hp_svc.values()\n",
    "    print(f'SVC: C={c_opt}, gamma={gamma_opt}')\n",
    "    svc = make_pipeline(StandardScaler(),\n",
    "                        SVC(C=c_opt,\n",
    "                            gamma=gamma_opt,\n",
    "                            kernel='rbf'\n",
    "                           )\n",
    "                       )\n",
    "    svc.fit(X_train,y_train)\n",
    "    pred_svc = svc.predict(X_test)\n",
    "    f1_svc = round(f1_score(y_test,pred_svc),2)\n",
    "    svc_score += f1_svc\n",
    "    \n",
    "    print(f\"\\nF1 scores: Trees={f1_tree}, KNN={f1_knn}, RF={f1_rf}, SGD={f1_sgd}, SVC={f1_svc}\\n\")\n",
    "    \n",
    "    rounds += 1\n",
    "\n",
    "print(f\"\\nTotal F1 scores: Trees={round(tree_score/rounds,2)}, KNN={round(knn_score/rounds,2)}, RF={round(rf_score/rounds,2)}, SGD={round(sgd_score/rounds,2)}, SVC = {round(svc_score/rounds,2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antobody Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t7565\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t7548\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t7548\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t7548\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t7548\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t15\n",
      "Rejected: \t7550\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t14\n",
      "Rejected: \t7551\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t11\n",
      "Rejected: \t7551\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t10\n",
      "Rejected: \t7551\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t4\n",
      "Tentative: \t10\n",
      "Rejected: \t7551\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t9\n",
      "Rejected: \t7551\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t6\n",
      "Rejected: \t7551\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t9\n",
      "Tentative: \t5\n",
      "Rejected: \t7551\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t4\n",
      "Rejected: \t7551\n"
     ]
    }
   ],
   "source": [
    "X_ar = X\n",
    "\n",
    "forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=15)\n",
    "forest.fit(np.array(X_ar), np.array(y_ar).ravel())\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=42)\n",
    "feat_selector.fit(np.array(X_ar), np.array(y_ar).ravel())\n",
    "feature_ranks_ar = list(zip(X_ar.columns, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "features_ar = []\n",
    "for feat in feature_ranks_ar:\n",
    "    if feat[2]:\n",
    "        features_ar.append(feat[0])\n",
    "X_ar = X_ar[features_ar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACP2</th>\n",
       "      <th>ADAP2</th>\n",
       "      <th>ADPRH</th>\n",
       "      <th>ANAPC1</th>\n",
       "      <th>ANKS6</th>\n",
       "      <th>ANO10</th>\n",
       "      <th>ANXA4</th>\n",
       "      <th>ARMC2</th>\n",
       "      <th>ATP1B3</th>\n",
       "      <th>BCRP3</th>\n",
       "      <th>...</th>\n",
       "      <th>ULK4</th>\n",
       "      <th>VAMP5</th>\n",
       "      <th>WDR52</th>\n",
       "      <th>XKRX</th>\n",
       "      <th>ZFYVE1</th>\n",
       "      <th>ZNF398</th>\n",
       "      <th>ZNF514</th>\n",
       "      <th>ZNF585A</th>\n",
       "      <th>ZNF714</th>\n",
       "      <th>ZNF860</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216143</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.259041</td>\n",
       "      <td>0.612129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.142284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185576</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497873</td>\n",
       "      <td>0.279551</td>\n",
       "      <td>0.209463</td>\n",
       "      <td>0.663312</td>\n",
       "      <td>0.784719</td>\n",
       "      <td>0.455902</td>\n",
       "      <td>0.865989</td>\n",
       "      <td>0.737856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788707</td>\n",
       "      <td>0.553989</td>\n",
       "      <td>0.306159</td>\n",
       "      <td>0.483360</td>\n",
       "      <td>0.385593</td>\n",
       "      <td>0.391554</td>\n",
       "      <td>0.402197</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.429520</td>\n",
       "      <td>0.725276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476914</td>\n",
       "      <td>0.295633</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.203325</td>\n",
       "      <td>0.341118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777085</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>0.509315</td>\n",
       "      <td>0.761494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.216055</td>\n",
       "      <td>0.094997</td>\n",
       "      <td>0.096638</td>\n",
       "      <td>0.720127</td>\n",
       "      <td>0.366089</td>\n",
       "      <td>0.782021</td>\n",
       "      <td>0.107275</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>0.275145</td>\n",
       "      <td>0.661197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127626</td>\n",
       "      <td>0.514514</td>\n",
       "      <td>0.425557</td>\n",
       "      <td>0.117262</td>\n",
       "      <td>0.683459</td>\n",
       "      <td>0.737132</td>\n",
       "      <td>0.149820</td>\n",
       "      <td>0.941905</td>\n",
       "      <td>0.345608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.187467</td>\n",
       "      <td>0.480658</td>\n",
       "      <td>0.237734</td>\n",
       "      <td>0.244861</td>\n",
       "      <td>0.347262</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669116</td>\n",
       "      <td>0.061770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442097</td>\n",
       "      <td>0.156629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>0.128178</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>0.675559</td>\n",
       "      <td>0.195768</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.245851</td>\n",
       "      <td>0.327142</td>\n",
       "      <td>0.346874</td>\n",
       "      <td>0.628496</td>\n",
       "      <td>0.261738</td>\n",
       "      <td>0.812663</td>\n",
       "      <td>0.407584</td>\n",
       "      <td>0.324182</td>\n",
       "      <td>0.243868</td>\n",
       "      <td>0.495378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387003</td>\n",
       "      <td>0.347763</td>\n",
       "      <td>0.534417</td>\n",
       "      <td>0.367324</td>\n",
       "      <td>0.195487</td>\n",
       "      <td>0.630931</td>\n",
       "      <td>0.700004</td>\n",
       "      <td>0.424789</td>\n",
       "      <td>0.532638</td>\n",
       "      <td>0.626687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.233488</td>\n",
       "      <td>0.321206</td>\n",
       "      <td>0.395521</td>\n",
       "      <td>0.409838</td>\n",
       "      <td>0.396621</td>\n",
       "      <td>0.795572</td>\n",
       "      <td>0.479224</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>0.596509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214242</td>\n",
       "      <td>0.282070</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.224232</td>\n",
       "      <td>0.583481</td>\n",
       "      <td>0.588801</td>\n",
       "      <td>0.387055</td>\n",
       "      <td>0.743491</td>\n",
       "      <td>0.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.284495</td>\n",
       "      <td>0.436058</td>\n",
       "      <td>0.506817</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.300965</td>\n",
       "      <td>0.175936</td>\n",
       "      <td>0.276953</td>\n",
       "      <td>0.483522</td>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.839591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410412</td>\n",
       "      <td>0.426324</td>\n",
       "      <td>0.242134</td>\n",
       "      <td>0.440611</td>\n",
       "      <td>0.237409</td>\n",
       "      <td>0.565331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231940</td>\n",
       "      <td>0.348611</td>\n",
       "      <td>0.346076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.554287</td>\n",
       "      <td>0.330217</td>\n",
       "      <td>0.477923</td>\n",
       "      <td>0.520196</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.205285</td>\n",
       "      <td>0.315097</td>\n",
       "      <td>0.090564</td>\n",
       "      <td>0.507282</td>\n",
       "      <td>0.416023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608063</td>\n",
       "      <td>0.531736</td>\n",
       "      <td>0.419974</td>\n",
       "      <td>0.250655</td>\n",
       "      <td>0.334245</td>\n",
       "      <td>0.439786</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.202911</td>\n",
       "      <td>0.470317</td>\n",
       "      <td>0.230329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797201</td>\n",
       "      <td>0.786282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.615539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827404</td>\n",
       "      <td>0.069521</td>\n",
       "      <td>0.863775</td>\n",
       "      <td>0.534817</td>\n",
       "      <td>0.062558</td>\n",
       "      <td>0.590323</td>\n",
       "      <td>0.706546</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.574692</td>\n",
       "      <td>0.619543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.309929</td>\n",
       "      <td>0.901286</td>\n",
       "      <td>0.290444</td>\n",
       "      <td>0.506823</td>\n",
       "      <td>0.351747</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.293003</td>\n",
       "      <td>0.992037</td>\n",
       "      <td>0.620429</td>\n",
       "      <td>0.682720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655056</td>\n",
       "      <td>0.393386</td>\n",
       "      <td>0.418158</td>\n",
       "      <td>0.190934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489851</td>\n",
       "      <td>0.701334</td>\n",
       "      <td>0.303695</td>\n",
       "      <td>0.391274</td>\n",
       "      <td>0.336442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.427187</td>\n",
       "      <td>0.607537</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.352575</td>\n",
       "      <td>0.234511</td>\n",
       "      <td>0.120998</td>\n",
       "      <td>0.834468</td>\n",
       "      <td>0.556786</td>\n",
       "      <td>0.542263</td>\n",
       "      <td>0.187160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146314</td>\n",
       "      <td>0.414019</td>\n",
       "      <td>0.092624</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>0.498879</td>\n",
       "      <td>0.294566</td>\n",
       "      <td>0.351390</td>\n",
       "      <td>0.376819</td>\n",
       "      <td>0.252306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.507364</td>\n",
       "      <td>0.304032</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0.067014</td>\n",
       "      <td>0.143015</td>\n",
       "      <td>0.476855</td>\n",
       "      <td>0.175512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497189</td>\n",
       "      <td>0.254863</td>\n",
       "      <td>0.290879</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.323758</td>\n",
       "      <td>0.486334</td>\n",
       "      <td>0.450231</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.202729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.637802</td>\n",
       "      <td>0.622149</td>\n",
       "      <td>0.372493</td>\n",
       "      <td>0.536564</td>\n",
       "      <td>0.135342</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>0.286660</td>\n",
       "      <td>0.535332</td>\n",
       "      <td>0.202790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.334113</td>\n",
       "      <td>0.117476</td>\n",
       "      <td>0.091267</td>\n",
       "      <td>0.513602</td>\n",
       "      <td>0.395996</td>\n",
       "      <td>0.595165</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.240012</td>\n",
       "      <td>0.455420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.712164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233351</td>\n",
       "      <td>0.353766</td>\n",
       "      <td>0.047280</td>\n",
       "      <td>0.281620</td>\n",
       "      <td>0.227725</td>\n",
       "      <td>0.507141</td>\n",
       "      <td>0.224540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334859</td>\n",
       "      <td>0.799059</td>\n",
       "      <td>0.183037</td>\n",
       "      <td>0.083448</td>\n",
       "      <td>0.502502</td>\n",
       "      <td>0.479159</td>\n",
       "      <td>0.289961</td>\n",
       "      <td>0.386077</td>\n",
       "      <td>0.134790</td>\n",
       "      <td>0.384195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546266</td>\n",
       "      <td>0.853013</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.041728</td>\n",
       "      <td>0.269375</td>\n",
       "      <td>0.562908</td>\n",
       "      <td>0.130593</td>\n",
       "      <td>0.831635</td>\n",
       "      <td>0.125026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176782</td>\n",
       "      <td>0.804406</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.127507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474033</td>\n",
       "      <td>0.301801</td>\n",
       "      <td>0.697518</td>\n",
       "      <td>0.212276</td>\n",
       "      <td>0.142425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.553230</td>\n",
       "      <td>0.824275</td>\n",
       "      <td>0.469560</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127096</td>\n",
       "      <td>0.763596</td>\n",
       "      <td>0.261175</td>\n",
       "      <td>0.673822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157839</td>\n",
       "      <td>0.897507</td>\n",
       "      <td>0.142556</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.463071</td>\n",
       "      <td>0.388711</td>\n",
       "      <td>0.371585</td>\n",
       "      <td>0.619165</td>\n",
       "      <td>0.200435</td>\n",
       "      <td>0.202366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.651492</td>\n",
       "      <td>0.308662</td>\n",
       "      <td>0.471186</td>\n",
       "      <td>0.168238</td>\n",
       "      <td>0.084161</td>\n",
       "      <td>0.340835</td>\n",
       "      <td>0.342975</td>\n",
       "      <td>0.503568</td>\n",
       "      <td>0.283776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315218</td>\n",
       "      <td>0.134342</td>\n",
       "      <td>0.400962</td>\n",
       "      <td>0.109481</td>\n",
       "      <td>0.404591</td>\n",
       "      <td>0.426768</td>\n",
       "      <td>0.693388</td>\n",
       "      <td>0.674862</td>\n",
       "      <td>0.413769</td>\n",
       "      <td>0.418440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.811242</td>\n",
       "      <td>0.985748</td>\n",
       "      <td>0.620292</td>\n",
       "      <td>0.377593</td>\n",
       "      <td>0.253626</td>\n",
       "      <td>0.183082</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>0.595812</td>\n",
       "      <td>0.223708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251420</td>\n",
       "      <td>0.943722</td>\n",
       "      <td>0.484844</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>0.303207</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>0.549964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310579</td>\n",
       "      <td>0.417145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.491870</td>\n",
       "      <td>0.317828</td>\n",
       "      <td>0.434757</td>\n",
       "      <td>0.405798</td>\n",
       "      <td>0.140243</td>\n",
       "      <td>0.445502</td>\n",
       "      <td>0.330143</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>0.508850</td>\n",
       "      <td>0.552611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.438985</td>\n",
       "      <td>0.239295</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>0.067644</td>\n",
       "      <td>0.288947</td>\n",
       "      <td>0.548016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274901</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.242129</td>\n",
       "      <td>0.474241</td>\n",
       "      <td>0.345219</td>\n",
       "      <td>0.304720</td>\n",
       "      <td>0.284575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413718</td>\n",
       "      <td>0.207677</td>\n",
       "      <td>0.299558</td>\n",
       "      <td>0.597283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486081</td>\n",
       "      <td>0.341977</td>\n",
       "      <td>0.398062</td>\n",
       "      <td>0.223016</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.375307</td>\n",
       "      <td>0.497516</td>\n",
       "      <td>0.468174</td>\n",
       "      <td>0.506965</td>\n",
       "      <td>0.537427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.232795</td>\n",
       "      <td>0.434043</td>\n",
       "      <td>0.539023</td>\n",
       "      <td>0.314190</td>\n",
       "      <td>0.385917</td>\n",
       "      <td>0.248484</td>\n",
       "      <td>0.292096</td>\n",
       "      <td>0.347730</td>\n",
       "      <td>0.328651</td>\n",
       "      <td>0.569873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138312</td>\n",
       "      <td>0.263434</td>\n",
       "      <td>0.094086</td>\n",
       "      <td>0.170160</td>\n",
       "      <td>0.347048</td>\n",
       "      <td>0.519534</td>\n",
       "      <td>0.286125</td>\n",
       "      <td>0.727484</td>\n",
       "      <td>0.337394</td>\n",
       "      <td>0.531916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.480606</td>\n",
       "      <td>0.213020</td>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.465058</td>\n",
       "      <td>0.242371</td>\n",
       "      <td>0.123568</td>\n",
       "      <td>0.203286</td>\n",
       "      <td>0.197685</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643800</td>\n",
       "      <td>0.167074</td>\n",
       "      <td>0.398216</td>\n",
       "      <td>0.431558</td>\n",
       "      <td>0.118979</td>\n",
       "      <td>0.956478</td>\n",
       "      <td>0.731018</td>\n",
       "      <td>0.212851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.420516</td>\n",
       "      <td>0.813491</td>\n",
       "      <td>0.702705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078291</td>\n",
       "      <td>0.238209</td>\n",
       "      <td>0.806365</td>\n",
       "      <td>0.585711</td>\n",
       "      <td>0.920696</td>\n",
       "      <td>0.059498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>0.074096</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.269461</td>\n",
       "      <td>0.310710</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>0.825994</td>\n",
       "      <td>0.230258</td>\n",
       "      <td>0.330634</td>\n",
       "      <td>0.671197</td>\n",
       "      <td>0.338659</td>\n",
       "      <td>0.309598</td>\n",
       "      <td>0.658353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236905</td>\n",
       "      <td>0.355602</td>\n",
       "      <td>0.157753</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>0.779279</td>\n",
       "      <td>0.751609</td>\n",
       "      <td>0.951779</td>\n",
       "      <td>0.320923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.571078</td>\n",
       "      <td>0.513024</td>\n",
       "      <td>0.518492</td>\n",
       "      <td>0.198639</td>\n",
       "      <td>0.198515</td>\n",
       "      <td>0.083307</td>\n",
       "      <td>0.654138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574537</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037588</td>\n",
       "      <td>0.502169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.955766</td>\n",
       "      <td>0.286406</td>\n",
       "      <td>0.702593</td>\n",
       "      <td>0.443951</td>\n",
       "      <td>0.411762</td>\n",
       "      <td>0.210630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.699299</td>\n",
       "      <td>0.655838</td>\n",
       "      <td>0.701347</td>\n",
       "      <td>0.113350</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.202401</td>\n",
       "      <td>0.182391</td>\n",
       "      <td>0.239908</td>\n",
       "      <td>0.385617</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199979</td>\n",
       "      <td>0.627654</td>\n",
       "      <td>0.086441</td>\n",
       "      <td>0.116217</td>\n",
       "      <td>0.634730</td>\n",
       "      <td>0.179377</td>\n",
       "      <td>0.194824</td>\n",
       "      <td>0.310331</td>\n",
       "      <td>0.098931</td>\n",
       "      <td>0.235341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.978650</td>\n",
       "      <td>0.835768</td>\n",
       "      <td>0.295552</td>\n",
       "      <td>0.177371</td>\n",
       "      <td>0.047372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181849</td>\n",
       "      <td>0.672842</td>\n",
       "      <td>0.324910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134317</td>\n",
       "      <td>0.924465</td>\n",
       "      <td>0.090459</td>\n",
       "      <td>0.241621</td>\n",
       "      <td>0.393861</td>\n",
       "      <td>0.425253</td>\n",
       "      <td>0.368332</td>\n",
       "      <td>0.718554</td>\n",
       "      <td>0.096660</td>\n",
       "      <td>0.271646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.145197</td>\n",
       "      <td>0.172238</td>\n",
       "      <td>0.582731</td>\n",
       "      <td>0.459690</td>\n",
       "      <td>0.485192</td>\n",
       "      <td>0.654421</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>0.274080</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208780</td>\n",
       "      <td>0.103252</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.196355</td>\n",
       "      <td>0.224907</td>\n",
       "      <td>0.186832</td>\n",
       "      <td>0.538360</td>\n",
       "      <td>0.460820</td>\n",
       "      <td>0.668912</td>\n",
       "      <td>0.379613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.099356</td>\n",
       "      <td>0.125264</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765422</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.152905</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.091137</td>\n",
       "      <td>0.357974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955028</td>\n",
       "      <td>0.311503</td>\n",
       "      <td>0.527487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184960</td>\n",
       "      <td>0.562726</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>0.279854</td>\n",
       "      <td>0.536827</td>\n",
       "      <td>0.562678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.335002</td>\n",
       "      <td>0.350859</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.532208</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>0.864813</td>\n",
       "      <td>0.331008</td>\n",
       "      <td>0.709021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246196</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>0.164171</td>\n",
       "      <td>0.185125</td>\n",
       "      <td>0.448114</td>\n",
       "      <td>0.614123</td>\n",
       "      <td>0.706983</td>\n",
       "      <td>0.428855</td>\n",
       "      <td>0.406522</td>\n",
       "      <td>0.674449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACP2     ADAP2     ADPRH    ANAPC1     ANKS6     ANO10     ANXA4  \\\n",
       "0   0.216143  0.010809  0.259041  0.612129  1.000000  0.417700  0.142284   \n",
       "1   0.788707  0.553989  0.306159  0.483360  0.385593  0.391554  0.402197   \n",
       "2   0.216055  0.094997  0.096638  0.720127  0.366089  0.782021  0.107275   \n",
       "3   0.187467  0.480658  0.237734  0.244861  0.347262  0.045505  0.000000   \n",
       "4   0.245851  0.327142  0.346874  0.628496  0.261738  0.812663  0.407584   \n",
       "5   0.233488  0.321206  0.395521  0.409838  0.396621  0.795572  0.479224   \n",
       "6   0.284495  0.436058  0.506817  0.529429  0.300965  0.175936  0.276953   \n",
       "7   0.554287  0.330217  0.477923  0.520196  0.150200  0.205285  0.315097   \n",
       "8   0.000000  0.000000  0.000000  0.797201  0.786282  1.000000  0.074137   \n",
       "9   0.309929  0.901286  0.290444  0.506823  0.351747  0.192963  0.293003   \n",
       "10  0.427187  0.607537  0.579617  0.352575  0.234511  0.120998  0.834468   \n",
       "11  0.394490  0.507364  0.304032  0.292536  0.067014  0.143015  0.476855   \n",
       "12  0.637802  0.622149  0.372493  0.536564  0.135342  0.097315  0.855416   \n",
       "13  0.712164  1.000000  1.000000  0.233351  0.353766  0.047280  0.281620   \n",
       "14  1.000000  0.546266  0.853013  0.286500  0.041728  0.269375  0.562908   \n",
       "15  0.553230  0.824275  0.469560  0.033299  0.000000  0.127096  0.763596   \n",
       "16  0.529487  0.651492  0.308662  0.471186  0.168238  0.084161  0.340835   \n",
       "17  0.811242  0.985748  0.620292  0.377593  0.253626  0.183082  0.841745   \n",
       "18  0.491870  0.317828  0.434757  0.405798  0.140243  0.445502  0.330143   \n",
       "19  0.242129  0.474241  0.345219  0.304720  0.284575  0.000000  0.413718   \n",
       "20  0.232795  0.434043  0.539023  0.314190  0.385917  0.248484  0.292096   \n",
       "21  0.175679  0.480606  0.213020  0.878027  0.465058  0.242371  0.123568   \n",
       "22  0.420516  0.813491  0.702705  0.000000  0.078291  0.238209  0.806365   \n",
       "23  0.269461  0.310710  0.614850  0.825994  0.230258  0.330634  0.671197   \n",
       "24  0.571078  0.513024  0.518492  0.198639  0.198515  0.083307  0.654138   \n",
       "25  0.699299  0.655838  0.701347  0.113350  0.052566  0.202401  0.182391   \n",
       "26  0.675269  0.978650  0.835768  0.295552  0.177371  0.047372  1.000000   \n",
       "27  0.145197  0.172238  0.582731  0.459690  0.485192  0.654421  0.222817   \n",
       "28  0.099356  0.125264  0.066578  1.000000  0.765422  0.695247  0.152905   \n",
       "29  0.009414  0.335002  0.350859  0.602721  0.532208  0.961957  0.179375   \n",
       "\n",
       "       ARMC2    ATP1B3     BCRP3  ...      ULK4     VAMP5     WDR52      XKRX  \\\n",
       "0   1.000000  0.185576  0.673869  ...  0.595176  0.000000  0.497873  0.279551   \n",
       "1   0.413500  0.429520  0.725276  ...  0.476914  0.295633  0.906812  0.203325   \n",
       "2   0.381808  0.275145  0.661197  ...  1.000000  0.127626  0.514514  0.425557   \n",
       "3   0.669116  0.061770  1.000000  ...  0.442097  0.156629  1.000000  0.072125   \n",
       "4   0.324182  0.243868  0.495378  ...  0.387003  0.347763  0.534417  0.367324   \n",
       "5   0.416163  0.472171  0.596509  ...  0.214242  0.282070  0.259378  0.370796   \n",
       "6   0.483522  0.467890  0.839591  ...  0.410412  0.426324  0.242134  0.440611   \n",
       "7   0.090564  0.507282  0.416023  ...  0.608063  0.531736  0.419974  0.250655   \n",
       "8   0.615539  0.000000  0.633228  ...  0.827404  0.069521  0.863775  0.534817   \n",
       "9   0.992037  0.620429  0.682720  ...  0.655056  0.393386  0.418158  0.190934   \n",
       "10  0.556786  0.542263  0.187160  ...  0.146314  0.414019  0.092624  0.048195   \n",
       "11  0.175512  1.000000  0.079819  ...  0.497189  0.254863  0.290879  0.116534   \n",
       "12  0.286660  0.535332  0.202790  ...  0.009578  0.334113  0.117476  0.091267   \n",
       "13  0.227725  0.507141  0.224540  ...  0.334859  0.799059  0.183037  0.083448   \n",
       "14  0.130593  0.831635  0.125026  ...  0.176782  0.804406  0.012535  0.127507   \n",
       "15  0.261175  0.673822  0.000000  ...  0.157839  0.897507  0.142556  0.058125   \n",
       "16  0.342975  0.503568  0.283776  ...  0.315218  0.134342  0.400962  0.109481   \n",
       "17  0.031184  0.595812  0.223708  ...  0.251420  0.943722  0.484844  0.076226   \n",
       "18  0.050584  0.508850  0.552611  ...  0.590909  0.438985  0.239295  0.046952   \n",
       "19  0.207677  0.299558  0.597283  ...  0.486081  0.341977  0.398062  0.223016   \n",
       "20  0.347730  0.328651  0.569873  ...  0.138312  0.263434  0.094086  0.170160   \n",
       "21  0.203286  0.197685  0.877882  ...  0.643800  0.167074  0.398216  0.431558   \n",
       "22  0.585711  0.920696  0.059498  ...  0.000000  1.000000  0.123037  0.074096   \n",
       "23  0.338659  0.309598  0.658353  ...  0.236905  0.355602  0.157753  0.142695   \n",
       "24  0.000000  0.574537  0.136819  ...  0.037588  0.502169  0.000000  0.013535   \n",
       "25  0.239908  0.385617  0.013386  ...  0.199979  0.627654  0.086441  0.116217   \n",
       "26  0.181849  0.672842  0.324910  ...  0.134317  0.924465  0.090459  0.241621   \n",
       "27  0.355530  0.274080  0.081900  ...  0.208780  0.103252  0.779081  0.196355   \n",
       "28  0.704698  0.091137  0.357974  ...  0.955028  0.311503  0.527487  1.000000   \n",
       "29  0.864813  0.331008  0.709021  ...  0.246196  0.051698  0.164171  0.185125   \n",
       "\n",
       "      ZFYVE1    ZNF398    ZNF514   ZNF585A    ZNF714    ZNF860  \n",
       "0   0.209463  0.663312  0.784719  0.455902  0.865989  0.737856  \n",
       "1   0.341118  1.000000  0.777085  0.156417  0.509315  0.761494  \n",
       "2   0.117262  0.683459  0.737132  0.149820  0.941905  0.345608  \n",
       "3   0.128178  0.653650  0.675559  0.195768  0.312223  1.000000  \n",
       "4   0.195487  0.630931  0.700004  0.424789  0.532638  0.626687  \n",
       "5   0.224232  0.583481  0.588801  0.387055  0.743491  0.440002  \n",
       "6   0.237409  0.565331  1.000000  0.231940  0.348611  0.346076  \n",
       "7   0.334245  0.439786  0.588235  0.202911  0.470317  0.230329  \n",
       "8   0.062558  0.590323  0.706546  0.208376  0.574692  0.619543  \n",
       "9   0.000000  0.489851  0.701334  0.303695  0.391274  0.336442  \n",
       "10  0.341188  0.498879  0.294566  0.351390  0.376819  0.252306  \n",
       "11  0.323758  0.486334  0.450231  0.697579  0.227790  0.202729  \n",
       "12  0.513602  0.395996  0.595165  0.302516  0.240012  0.455420  \n",
       "13  0.502502  0.479159  0.289961  0.386077  0.134790  0.384195  \n",
       "14  1.000000  0.474033  0.301801  0.697518  0.212276  0.142425  \n",
       "15  0.463071  0.388711  0.371585  0.619165  0.200435  0.202366  \n",
       "16  0.404591  0.426768  0.693388  0.674862  0.413769  0.418440  \n",
       "17  0.303207  0.427715  0.549964  1.000000  0.310579  0.417145  \n",
       "18  0.067644  0.288947  0.548016  0.000000  0.274901  0.000000  \n",
       "19  0.541633  0.375307  0.497516  0.468174  0.506965  0.537427  \n",
       "20  0.347048  0.519534  0.286125  0.727484  0.337394  0.531916  \n",
       "21  0.118979  0.956478  0.731018  0.212851  1.000000  0.654554  \n",
       "22  0.243477  0.000000  0.000000  0.459146  0.000000  0.084990  \n",
       "23  0.210738  0.509198  0.779279  0.751609  0.951779  0.320923  \n",
       "24  0.955766  0.286406  0.702593  0.443951  0.411762  0.210630  \n",
       "25  0.634730  0.179377  0.194824  0.310331  0.098931  0.235341  \n",
       "26  0.393861  0.425253  0.368332  0.718554  0.096660  0.271646  \n",
       "27  0.224907  0.186832  0.538360  0.460820  0.668912  0.379613  \n",
       "28  0.184960  0.562726  0.687471  0.279854  0.536827  0.562678  \n",
       "29  0.448114  0.614123  0.706983  0.428855  0.406522  0.674449  \n",
       "\n",
       "[30 rows x 100 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ar = X\n",
    "anova =  SelectKBest(f_classif, k=100).fit(X_ar, y_ar)\n",
    "X_ar = pd.DataFrame(anova.fit_transform(X_ar,y_ar))\n",
    "index = np.where(anova.get_support()==True)\n",
    "X_ar.columns = genes[index]\n",
    "X_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Trees: max_depth=1, criterion=gini\n",
      "KNN: n_neighbors=4, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=hinge, alpha=0.01, penalty=l2\n",
      "SVC: C=5, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.67, KNN=0.75, RF=0.8, SGD=0.75, SVC=0.75\n",
      "\n",
      "Round 2:\n",
      "Trees: max_depth=2, criterion=gini\n",
      "KNN: n_neighbors=1, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=perceptron, alpha=0.0001, penalty=l2\n",
      "SVC: C=1, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.67, KNN=1.0, RF=0.86, SGD=0.86, SVC=0.86\n",
      "\n",
      "Round 3:\n",
      "Trees: max_depth=1, criterion=gini\n",
      "KNN: n_neighbors=1, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=perceptron, alpha=0.1, penalty=l2\n",
      "SVC: C=5, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.86, KNN=0.86, RF=1.0, SGD=1.0, SVC=1.0\n",
      "\n",
      "Round 4:\n",
      "Trees: max_depth=3, criterion=gini\n",
      "KNN: n_neighbors=5, algorithm=auto\n",
      "RF: n_estimators=158\n",
      "SGD: loss=hinge, alpha=0.01, penalty=elasticnet\n",
      "SVC: C=5, gamma=auto\n",
      "\n",
      "F1 scores: Trees=0.57, KNN=0.67, RF=0.86, SGD=0.86, SVC=0.86\n",
      "\n",
      "Round 5:\n",
      "Trees: max_depth=1, criterion=gini\n",
      "KNN: n_neighbors=3, algorithm=auto\n",
      "RF: n_estimators=150\n",
      "SGD: loss=hinge, alpha=0.001, penalty=elasticnet\n",
      "SVC: C=1, gamma=scale\n",
      "\n",
      "F1 scores: Trees=0.57, KNN=0.89, RF=0.57, SGD=0.89, SVC=0.89\n",
      "\n",
      "\n",
      "Total F1 scores: Trees=1.45, KNN=1.73, RF=1.71, SGD=1.77, SVC = 1.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "test_size = 0.3\n",
    "n_folds = 5\n",
    "kfold = KFold(n_folds,shuffle=True,random_state=42)\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "#Decision Trees\n",
    "param_grid_tree = {'max_depth':[1,2,3,4,5],\n",
    "                   'criterion':['gini','entropy']\n",
    "                  }\n",
    "\n",
    "#KNN\n",
    "param_grid_knn = {'n_neighbors':[1,2,3,4,5],\n",
    "                  'algorithm':['auto','ball_tree','kd_tree','brute']\n",
    "                 }\n",
    "\n",
    "#Random Forest\n",
    "param_grid_rf = {'n_estimators':[150,158,166,174,182]}\n",
    "\n",
    "#SGD\n",
    "param_grid_sgd = {'loss':['hinge', 'perceptron'],\n",
    "                 'penalty':['l2', 'l1', 'elasticnet'],\n",
    "                 'alpha':[1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "                 }\n",
    "\n",
    "#SVC\n",
    "param_grid_svc = {'C':[1, 5, 10, 50, 100,],\n",
    "                  'gamma':['scale','auto']\n",
    "                 }\n",
    "\n",
    "rounds = 0\n",
    "\n",
    "for train_index, test_index in sss.split(X_ar, y_ar):\n",
    "    print(f'Round {rounds+1}:')\n",
    "    X_train,X_test,y_train,y_test = X_ar.iloc[train_index],X_ar.iloc[test_index],y_ar.iloc[train_index],y_ar.iloc[test_index]\n",
    "    \n",
    "    #Decision trees\n",
    "    hp_tree= get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_tree,DecisionTreeClassifier(random_state=42))\n",
    "    criterion_opt,max_depth_opt = hp_tree.values()\n",
    "    print(f'Trees: max_depth={max_depth_opt}, criterion={criterion_opt}')\n",
    "    tree = make_pipeline(StandardScaler(),\n",
    "                         DecisionTreeClassifier(\n",
    "                            random_state=42,\n",
    "                            criterion=criterion_opt,\n",
    "                            max_depth=max_depth_opt,\n",
    "                         )\n",
    "                        )\n",
    "    tree.fit(X_train,y_train)\n",
    "    pred_tree = tree.predict(X_test)\n",
    "    f1_tree = round(f1_score(y_test,pred_tree),2)\n",
    "    tree_score += f1_tree\n",
    "    \n",
    "    #KNN\n",
    "    hp_knn = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_knn,KNeighborsClassifier())\n",
    "    algorithm_opt,n_neighbors_opt = hp_knn.values()\n",
    "    print(f'KNN: n_neighbors={n_neighbors_opt}, algorithm={algorithm_opt}')\n",
    "    knn = make_pipeline(StandardScaler(),\n",
    "                        KNeighborsClassifier(\n",
    "                            n_neighbors=n_neighbors_opt,\n",
    "                            algorithm=algorithm_opt\n",
    "                        )\n",
    "                       )\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_knn = knn.predict(X_test)\n",
    "    f1_knn = round(f1_score(y_test,pred_knn),2)\n",
    "    knn_score += f1_knn\n",
    "    \n",
    "    #Random Forest\n",
    "    hp_rf = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_rf,RandomForestClassifier())\n",
    "    n_estimators_opt = list(hp_rf.values())[0]\n",
    "    print(f'RF: n_estimators={n_estimators_opt}')\n",
    "    rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(\n",
    "                            n_estimators=n_estimators_opt\n",
    "                        )\n",
    "                       )\n",
    "    rf.fit(X_train,y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "    f1_rf = round(f1_score(y_test,pred_rf),2)\n",
    "    rf_score += f1_rf\n",
    "    \n",
    "    #SGD\n",
    "    hp_sgd = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_sgd,SGDClassifier())\n",
    "    alpha_opt,loss_opt,penalty_opt = hp_sgd.values()\n",
    "    print(f'SGD: loss={loss_opt}, alpha={alpha_opt}, penalty={penalty_opt}')\n",
    "    sgd = make_pipeline(StandardScaler(),\n",
    "                        SGDClassifier(\n",
    "                            loss=loss_opt,\n",
    "                            alpha=alpha_opt,\n",
    "                            penalty=penalty_opt\n",
    "                        )\n",
    "                       )\n",
    "    sgd.fit(X_train,y_train)\n",
    "    pred_sgd = sgd.predict(X_test)\n",
    "    f1_sgd = round(f1_score(y_test,pred_sgd),2)\n",
    "    sgd_score += f1_sgd\n",
    "    \n",
    "    #SVC\n",
    "    hp_svc = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid_svc,SVC())\n",
    "    c_opt,gamma_opt = hp_svc.values()\n",
    "    print(f'SVC: C={c_opt}, gamma={gamma_opt}')\n",
    "    svc = make_pipeline(StandardScaler(),\n",
    "                        SVC(C=c_opt,\n",
    "                            gamma=gamma_opt,\n",
    "                            kernel='rbf'\n",
    "                           )\n",
    "                       )\n",
    "    svc.fit(X_train,y_train)\n",
    "    pred_svc = svc.predict(X_test)\n",
    "    f1_svc = round(f1_score(y_test,pred_svc),2)\n",
    "    svc_score += f1_svc\n",
    "    \n",
    "    print(f\"\\nF1 scores: Trees={f1_tree}, KNN={f1_knn}, RF={f1_rf}, SGD={f1_sgd}, SVC={f1_svc}\\n\")\n",
    "    \n",
    "    rounds += 1\n",
    "\n",
    "print(f\"\\nTotal F1 scores: Trees={round(tree_score/rounds,2)}, KNN={round(knn_score/rounds,2)}, RF={round(rf_score/rounds,2)}, SGD={round(sgd_score/rounds,2)}, SVC = {round(svc_score/rounds,2)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python36764bitae56fdbcc1594148b699def9b739fd1e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
