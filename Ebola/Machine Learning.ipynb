{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17165284904607196673\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4687451711350978828\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3127299276\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15240611386881885801\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11426148042223561868\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor,ElasticNet,RidgeCV, LinearRegression\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\\\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dropout, BatchNormalization, Input, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_genes_RFE(X,y,estimators,num_genes_fold,num_genes_final,folds):\n",
    "    genes_related = []\n",
    "    \n",
    "    for estimator in estimators:\n",
    "        selector = RFECV(estimator, min_features_to_select=num_genes_fold, cv=folds, step=1)\n",
    "        selector = selector.fit(X, y)\n",
    "        ranking = selector.ranking_\n",
    "        ranking_idx = ranking.argsort()[-num_genes_fold:][::-1]\n",
    "        genes_related+=list(X.columns[ranking_idx])\n",
    "\n",
    "    dic_count = Counter(genes_related)\n",
    "    dic_count = {k: v for k, v in sorted(dic_count.items(), key=lambda item: item[1])}\n",
    "    top_genes = list(dic_count.keys())[-num_genes_final:]\n",
    "    return top_genes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid, model,w,h,df,plot,annot):\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,\n",
    "                      param_grid=param_grid,\n",
    "                      cv=kfold)\n",
    "    best_gs = gs.fit(X_train,y_train)\n",
    "    n = len(param_grid)\n",
    "    scores = best_gs.cv_results_['mean_test_score']\n",
    "    scores = scores.reshape(len(scores),)\n",
    "    \n",
    "    if n == 1:\n",
    "        label = list(param_grid.keys())[0]\n",
    "        par = list(param_grid.values())[0]\n",
    "        plt.plot(par,scores)\n",
    "        plt.ylabel('F1-score')\n",
    "        plt.xlabel(label)\n",
    "        plt.show()\n",
    "        \n",
    "    if n == 2:\n",
    "        \n",
    "        label1,label2 = param_grid.keys()\n",
    "        par1,par2 = param_grid.values()\n",
    "        scores_df = pd.DataFrame(columns=par1,index=par2)\n",
    "        for i in range(len(par1)*len(par2)):\n",
    "            col = i % len(par1)\n",
    "            row = i // len(par1)\n",
    "            scores_df.iloc[row,col] = scores[i]\n",
    "\n",
    "        scores_df = scores_df.astype(float)\n",
    "        if df:\n",
    "            print(scores_df)\n",
    "        if plot:\n",
    "            fig= plt.figure(figsize=(w,h))\n",
    "            heatmap = sns.heatmap(scores_df,annot=annot)        \n",
    "            plt.xlabel(label1)\n",
    "            plt.ylabel(label2)\n",
    "            plt.show()\n",
    "\n",
    "    return best_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_388 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_392 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_396 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_400 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_404 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_408 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_412 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Index(['AREG', 'BCL2', 'CASP8', 'CD3E', 'CD274', 'CLEC7A', 'CXCL13', 'FASLG',\n",
      "       'FLCN1', 'FPR1', 'GBP5', 'IL12B', 'IL23A', 'MARCO', 'MRC2', 'NCAM1',\n",
      "       'NLRP1', 'NLRP3', 'NLRP6', 'NLRP7', 'NLRP10', 'NLRP12', 'NOD2', 'RAB24',\n",
      "       'SEC14L1', 'SPP1', 'STAT2', 'TAGAP', 'TAP1', 'TGFBR2', 'TIMP2', 'TLR1',\n",
      "       'TLR2', 'TLR5', 'TLR8', 'TLR10', 'TNFRSF1A', 'TNFRSF1B'],\n",
      "      dtype='object')\n",
      "WARNING:tensorflow:Layer dense_416 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision_trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decision_trees\n",
       "0            0.70\n",
       "1            0.85\n",
       "2            0.68\n",
       "3            0.54\n",
       "4            0.61\n",
       "5            0.46\n",
       "6            0.59\n",
       "7            0.80"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 4\n",
    "test_size = 0.3 #Hp\n",
    "num_genes_fold = 15\n",
    "num_genes_final = 5\n",
    "folds = 10\n",
    "events = os.listdir('Dados/Eventos adversos')\n",
    "metrics = pd.DataFrame()\n",
    "metrics_ = []\n",
    "\n",
    "n_folds = 4\n",
    "test_size = 0.35\n",
    "\n",
    "kfold = KFold(n_folds,shuffle=True,random_state=42)\n",
    "\n",
    "max_depth = 20\n",
    "depths = [i for i in range(1,max_depth+1)]\n",
    "param_grid = {'max_depth':depths,\n",
    "              'splitter':['best', 'random'],\n",
    "              'criterion':['gini','entropy']\n",
    "             }\n",
    "# pca = PCA(n_components=num_genes_final)\n",
    "\n",
    "for event in events:\n",
    "    dados = pd.read_csv(f'Dados/Eventos adversos/{event}')\n",
    "    \n",
    "    X = dados.iloc[:,:-1]\n",
    "    y = dados.iloc[:,-1]\n",
    "    genes = list(X.columns)\n",
    "#     genes = get_genes_RFE(X,y,estimators,num_genes_fold,num_genes_final,folds)\n",
    "    genes_dl = get_genes_dl(X,y,estimators,test_size,num_genes_fold,num_genes_final,folds)\n",
    "    \n",
    "    X = X[genes_dl]\n",
    "#     X = pd.DataFrame(pca.fit_transform(X))\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "    tree_score = 0.0\n",
    "\n",
    "    for train_index, test_index in sss.split(X, y):    \n",
    "        X_train,X_test,y_train,y_test = X.iloc[train_index],X.iloc[test_index],y.iloc[train_index],y.iloc[test_index]\n",
    "        hp = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid,DecisionTreeClassifier(random_state=42,),10,6,False,False,False)\n",
    "        criterion_opt,max_depth_opt,splitter_opt = hp.values()\n",
    "        #Decision Trees\n",
    "        tree = make_pipeline(StandardScaler(),\n",
    "                            DecisionTreeClassifier(random_state=42,\n",
    "                                                   criterion=criterion_opt,\n",
    "                                                   max_depth=max_depth_opt,\n",
    "                                                   splitter=splitter_opt))\n",
    "\n",
    "        tree.fit(X_train,y_train)\n",
    "        pred_tree = tree.predict(X_test)\n",
    "        tree_score += f1_score(y_test,pred_tree,average='weighted',pos_label=\"Plano ID\")\n",
    "\n",
    "    tree_score /= float(n_splits)\n",
    "    \n",
    "    tree_score = round(tree_score,2)\n",
    "    \n",
    "    metrics_.append(tree_score)\n",
    "\n",
    "#     print(f\"F1-score for {event[:-4]}: Decision Trees: {tree_score}\")\n",
    "\n",
    "metrics['Decision_trees'] = metrics_\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for # of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: Decision Trees: 65.0%\n"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv('Dados/dados soma.csv')\n",
    "\n",
    "X_soma = dados.iloc[:,:-1]\n",
    "y_soma = dados.iloc[:,-1]\n",
    "\n",
    "estimators = [SVR(kernel='linear'),\n",
    "              SGDRegressor(),\n",
    "              ElasticNet(),\n",
    "              RidgeCV(),\n",
    "              LinearRegression()]\n",
    "\n",
    "genes = get_genes(X_soma,y_soma,estimators,num_genes_fold,num_genes_final,folds)\n",
    "X_soma = X_soma[genes]\n",
    "\n",
    "n_splits = 4\n",
    "test_size = 0.3 \n",
    "num_genes_fold = 15\n",
    "num_genes_final = 8\n",
    "folds = 10\n",
    "\n",
    "n_folds = 4\n",
    "test_size = 0.35\n",
    "\n",
    "kfold = KFold(n_folds,shuffle=True,random_state=42)\n",
    "\n",
    "max_depth = 20\n",
    "depths = [i for i in range(1,max_depth+1)]\n",
    "param_grid = {'max_depth':depths,\n",
    "              'splitter':['best', 'random'],\n",
    "              'criterion':['gini','entropy']\n",
    "             }\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "tree_score = 0.0\n",
    "\n",
    "for train_index, test_index in sss.split(X_soma, y_soma):    \n",
    "    X_train,X_test,y_train,y_test = X_soma.iloc[train_index],X_soma.iloc[test_index],y_soma.iloc[train_index],y_soma.iloc[test_index]\n",
    "    hp = get_hiperparams(X_train,X_test,y_train,y_test,kfold,param_grid,DecisionTreeClassifier(random_state=42,),10,6,False,False,False)\n",
    "    criterion_opt,max_depth_opt,splitter_opt = hp.values()\n",
    "\n",
    "    #Decision Trees\n",
    "    tree = make_pipeline(StandardScaler(),\n",
    "                        DecisionTreeClassifier(random_state=42,\n",
    "                                               criterion=criterion_opt,\n",
    "                                               max_depth=max_depth_opt,\n",
    "                                               splitter=splitter_opt))\n",
    "\n",
    "    tree.fit(X_train,y_train)\n",
    "    pred_tree = tree.predict(X_test)\n",
    "    tree_score += f1_score(y_test,pred_tree,average='weighted',pos_label=\"Plano ID\")\n",
    "\n",
    "tree_score /= float(n_splits)\n",
    "\n",
    "tree_score = round(tree_score,2)\n",
    "\n",
    "\n",
    "print(f\"F1-score: Decision Trees: {tree_score*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genes_dl(X,y,estimators,test_size,num_genes_fold,num_genes_final,folds):\n",
    "    \n",
    "    input_size = X.shape[1]\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size)\n",
    "    \n",
    "    model = Sequential()\n",
    "    activation_dense = 'relu'\n",
    "    model.add(Dense(X.shape[1], activation=activation_dense)) \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation=activation_dense)) \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation=activation_dense))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    hist= model.fit( X_train, \n",
    "                     y_train, \n",
    "                     batch_size=32, \n",
    "                     epochs=epochs, \n",
    "                     shuffle='True', \n",
    "                     validation_data=(X_test, y_test),\n",
    "                     verbose=0)\n",
    "    # get the first layer weights.\n",
    "    weights = model.layers[1].get_weights()[0]\n",
    "\n",
    "    # get the feature importance.\n",
    "    importance = weights.sum(axis = 1)\n",
    "    imp_idx = np.argsort(importance)[-num_genes_final:]\n",
    "    genes_dl = list(genes[imp_idx])\n",
    "    return genes_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: Arthralgia\n",
      "Genes selected by RFE:['TLR8', 'NLRP7', 'NLRP12', 'FLCN1', 'IL12B', 'CXCL13', 'MARCO', 'GBP5']\n",
      "Genes selectred by MLP:['NLRP10', 'NOD2', 'TIMP2', 'MARCO', 'TLR5', 'FPR1', 'SPP1', 'MRC2']\n",
      "\n",
      "Event: Arthritis\n",
      "Genes selected by RFE:['NLRP1', 'CD3E', 'MRC2', 'MARCO', 'FASLG', 'IL12B', 'CD274', 'GBP5']\n",
      "Genes selectred by MLP:['TAGAP', 'GBP5', 'TNFRSF1B', 'MARCO', 'NLRP7', 'NLRP6', 'FLCN1', 'NLRP1']\n",
      "\n",
      "Event: Chills\n",
      "Genes selected by RFE:['GBP5', 'FPR1', 'MRC2', 'IL23A', 'FLCN1', 'MARCO', 'IL12B', 'CXCL13']\n",
      "Genes selectred by MLP:['NCAM1', 'GBP5', 'IL23A', 'NOD2', 'TLR8', 'RAB24', 'TIMP2', 'CD3E']\n",
      "\n",
      "Event: Fatigue\n",
      "Genes selected by RFE:['FLCN1', 'GBP5', 'CLEC7A', 'CD274', 'MARCO', 'IL12B', 'CXCL13', 'MRC2']\n",
      "Genes selectred by MLP:['NLRP7', 'NCAM1', 'CD3E', 'NLRP1', 'STAT2', 'CD274', 'NLRP10', 'TLR10']\n",
      "\n",
      "Event: Fever\n",
      "Genes selected by RFE:['FLCN1', 'FASLG', 'MARCO', 'GBP5', 'IL12B', 'CLEC7A', 'CD274', 'CXCL13']\n",
      "Genes selectred by MLP:['TGFBR2', 'TNFRSF1A', 'NLRP6', 'CXCL13', 'NLRP1', 'TAGAP', 'FASLG', 'IL12B']\n",
      "\n",
      "Event: Headache\n",
      "Genes selected by RFE:['CD3E', 'IL23A', 'NLRP3', 'IL12B', 'BCL2', 'FLCN1', 'MARCO', 'MRC2']\n",
      "Genes selectred by MLP:['TLR1', 'BCL2', 'TLR5', 'CD3E', 'TLR10', 'NLRP10', 'RAB24', 'FLCN1']\n",
      "\n",
      "Event: Myalgia\n",
      "Genes selected by RFE:['NLRP7', 'CLEC7A', 'BCL2', 'IL12B', 'MARCO', 'FLCN1', 'FPR1', 'MRC2']\n",
      "Genes selectred by MLP:['NOD2', 'CLEC7A', 'TIMP2', 'TLR8', 'IL23A', 'CXCL13', 'NLRP7', 'TLR1']\n",
      "\n",
      "Event: Nausea\n",
      "Genes selected by RFE:['BCL2', 'FASLG', 'NCAM1', 'CLEC7A', 'MARCO', 'IL12B', 'IL23A', 'CD274']\n",
      "Genes selectred by MLP:['TGFBR2', 'FASLG', 'FPR1', 'NLRP7', 'NLRP1', 'TLR5', 'CD274', 'MRC2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "test_size = 0.3 \n",
    "num_genes_fold = 15\n",
    "num_genes_final = 8\n",
    "folds = 10\n",
    "\n",
    "estimators = [SVR(kernel='linear'),\n",
    "              SGDRegressor(),\n",
    "              ElasticNet(),\n",
    "              RidgeCV(),\n",
    "              LinearRegression()]\n",
    "\n",
    "events = os.listdir('Dados/Eventos adversos')\n",
    "for event in events:\n",
    "    dados = pd.read_csv(f'Dados/Eventos adversos/{event}')    \n",
    "    X = dados.iloc[:,:-1]\n",
    "    y = dados.iloc[:,-1]\n",
    "    genes = X.columns\n",
    "    genes_ml = get_genes(X,y,estimators,num_genes_fold,num_genes_final,folds)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape((y.shape[0],1))\n",
    "    genes_dl = get_genes_dl(X,y,estimators,test_size,num_genes_fold,num_genes_final,folds)\n",
    "    print(f'Event: {event[:-4]}\\nGenes selected by RFE:{genes_ml}\\nGenes selectred by MLP:{genes_dl}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
